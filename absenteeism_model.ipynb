{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    CLASSIFICATION IN MACHINE LEARNING USING\n",
    "                                                    i)logistic regression(sklearn)\n",
    "                                                    ii)neural network\n",
    "                                                    iii)random forest classifier\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING RELEVANT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential,optimizers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\HP\\Desktop\\Absenteeism\")\n",
    "df_preprocessed=pd.read_csv(\"Absenteeism_preprocessed_data.csv\")\n",
    "df_preprocessed=df_preprocessed.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['Targets']=np.where(df_preprocessed[\"Absenteeism Time in Hours\"]>np.median(df_preprocessed['Absenteeism Time in Hours']),1,0) #define categorical target\n",
    "df_preprocessed=df_preprocessed.drop(\"Absenteeism Time in Hours\",axis=1) #drop original target as we are only concerned with the binary outcomes\n",
    "inputs=df_preprocessed.iloc[:,0:14] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets=df_preprocessed['Targets']\n",
    "targets=np.array(targets)\n",
    "np.unique(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 14)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the datset into training and testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 14) (595, 14) \n",
      " (105,) (595,)\n",
      "(60, 14) (535, 14) \n",
      " (60,) (535,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason1</th>\n",
       "      <th>reason2</th>\n",
       "      <th>reason3</th>\n",
       "      <th>reason4</th>\n",
       "      <th>month</th>\n",
       "      <th>week_day</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.036026</td>\n",
       "      <td>0.074838</td>\n",
       "      <td>0.562059</td>\n",
       "      <td>-0.458497</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.016322</td>\n",
       "      <td>-1.209478</td>\n",
       "      <td>-0.379188</td>\n",
       "      <td>1.366488</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>-0.263140</td>\n",
       "      <td>-1.320435</td>\n",
       "      <td>-0.853789</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.854936</td>\n",
       "      <td>-1.682647</td>\n",
       "      <td>0.405184</td>\n",
       "      <td>2.677510</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>-0.263140</td>\n",
       "      <td>-1.320435</td>\n",
       "      <td>0.326336</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.654143</td>\n",
       "      <td>1.426749</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>-0.806331</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.036026</td>\n",
       "      <td>0.074838</td>\n",
       "      <td>0.562059</td>\n",
       "      <td>0.560476</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.016322</td>\n",
       "      <td>-1.209478</td>\n",
       "      <td>-0.379188</td>\n",
       "      <td>1.456728</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>1.223963</td>\n",
       "      <td>1.973929</td>\n",
       "      <td>0.326336</td>\n",
       "      <td>2.178644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.568211</td>\n",
       "      <td>1.359154</td>\n",
       "      <td>-0.065439</td>\n",
       "      <td>-1.647399</td>\n",
       "      <td>-0.878984</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reason1  reason2  reason3  reason4  month  week_day  \\\n",
       "75         1        0        0        0     10         2   \n",
       "199        1        0        0        0      4         3   \n",
       "696        1        0        0        0      5         3   \n",
       "213        0        0        0        0      5         3   \n",
       "515        0        0        0        1     10         2   \n",
       "..       ...      ...      ...      ...    ...       ...   \n",
       "5          0        0        0        1      7         5   \n",
       "281        0        0        0        1      9         5   \n",
       "360        0        0        0        1      1         1   \n",
       "507        1        0        0        0     10         4   \n",
       "23         0        0        0        1      8         5   \n",
       "\n",
       "     Transportation Expense  Distance to Work       Age  \\\n",
       "75                 1.036026          0.074838  0.562059   \n",
       "199               -1.016322         -1.209478 -0.379188   \n",
       "696                0.040034         -0.263140 -1.320435   \n",
       "213                0.854936         -1.682647  0.405184   \n",
       "515                0.040034         -0.263140 -1.320435   \n",
       "..                      ...               ...       ...   \n",
       "5                 -0.654143          1.426749  0.248310   \n",
       "281                1.036026          0.074838  0.562059   \n",
       "360               -1.016322         -1.209478 -0.379188   \n",
       "507                1.005844          1.223963  1.973929   \n",
       "23                 0.568211          1.359154 -0.065439   \n",
       "\n",
       "     Daily Work Load Average  Body Mass Index  Education  Children  Pets  \n",
       "75                 -0.458497        -0.408580          1         1     1  \n",
       "199                 1.366488        -0.408580          1         2     0  \n",
       "696                -0.853789        -0.643782          1         1     2  \n",
       "213                 2.677510        -0.643782          1         2     0  \n",
       "515                 0.326336        -0.643782          1         1     2  \n",
       "..                       ...              ...        ...       ...   ...  \n",
       "5                  -0.806331         1.002633          1         0     0  \n",
       "281                 0.560476        -0.408580          1         1     1  \n",
       "360                 1.456728        -0.408580          1         2     0  \n",
       "507                 0.326336         2.178644          1         0     2  \n",
       "23                 -1.647399        -0.878984          1         4     0  \n",
       "\n",
       "[535 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(inputs,targets,train_size=0.85,random_state=10)\n",
    "print(x_test.shape,x_train.shape ,\"\\n\",y_test.shape,y_train.shape)\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,train_size=0.9,random_state=10)\n",
    "print(x_val.shape,x_train.shape ,\"\\n\",y_val.shape,y_train.shape)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. USING LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score using builtin function: 0.7428571428571429\n",
      "\n",
      "checking manually\n",
      "\t\t\t\taccuracy_matrix\n",
      " [0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1]\n",
      "\n",
      "score: 0.7428571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "reg_model=LogisticRegression()\n",
    "reg_model.fit(x_train,y_train)\n",
    "print(\"score using builtin function:\",reg_model.score(x_test,y_test))\n",
    "print(\"\\nchecking manually\")\n",
    "predicted=reg_model.predict(x_test)\n",
    "accuracy_matrix=np.array([int(val) for val in predicted==y_test])\n",
    "print(\"\\t\\t\\t\\taccuracy_matrix\\n\",accuracy_matrix)\n",
    "print(\"\\nscore:\",sum(accuracy_matrix)/accuracy_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reason1</td>\n",
       "      <td>2.966127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reason3</td>\n",
       "      <td>2.959682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intercept</td>\n",
       "      <td>-1.684784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reason4</td>\n",
       "      <td>1.095586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reason2</td>\n",
       "      <td>0.826448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.533247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.410194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.284627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.234342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.174425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>week_day</td>\n",
       "      <td>-0.139668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Education</td>\n",
       "      <td>-0.066205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Daily Work Load Average</td>\n",
       "      <td>-0.036857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Distance to Work</td>\n",
       "      <td>0.025988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>month</td>\n",
       "      <td>0.021878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   features      coef\n",
       "0                   reason1  2.966127\n",
       "2                   reason3  2.959682\n",
       "0                 intercept -1.684784\n",
       "3                   reason4  1.095586\n",
       "1                   reason2  0.826448\n",
       "6    Transportation Expense  0.533247\n",
       "12                 Children  0.410194\n",
       "13                     Pets -0.284627\n",
       "8                       Age -0.234342\n",
       "10          Body Mass Index  0.174425\n",
       "5                  week_day -0.139668\n",
       "11                Education -0.066205\n",
       "9   Daily Work Load Average -0.036857\n",
       "7          Distance to Work  0.025988\n",
       "4                     month  0.021878"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=inputs.columns.values\n",
    "coefficents=reg_model.coef_[0]\n",
    "\n",
    "df_reg=pd.DataFrame({\"features\": features,\"coef\":coefficents})\n",
    "df_reg=pd.concat([df_reg,pd.DataFrame({\"features\":\"intercept\",\"coef\":reg_model.intercept_})],axis=0)\n",
    "df_reg['abs_coef']=df_reg['coef'].abs()\n",
    "df_reg=df_reg.sort_values(by=\"abs_coef\",ascending=False)\n",
    "df_reg=df_reg.drop('abs_coef',axis=1)\n",
    "df_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('absenteeism_logistic_model','wb')\n",
    "pickle.dump(reg_model,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II.USING NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_size=14\n",
    "hidden_size=300\n",
    "output_size=1\n",
    "\n",
    "\n",
    "nn_model=Sequential([\n",
    "    Dense(hidden_size,activation='tanh'),\n",
    "    Dense(hidden_size,activation='tanh'),\n",
    "    Dense(output_size,activation='sigmoid')])\n",
    "\n",
    "\n",
    "optimizer=optimizers.Adam(learning_rate=0.0001)\n",
    "nn_model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 4s 43ms/step - loss: 0.6790 - accuracy: 0.5439 - val_loss: 0.6271 - val_accuracy: 0.6500\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6422 - accuracy: 0.6523 - val_loss: 0.5885 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6258 - accuracy: 0.6430 - val_loss: 0.5634 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6184 - accuracy: 0.6523 - val_loss: 0.5536 - val_accuracy: 0.7167\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6005 - accuracy: 0.6991 - val_loss: 0.5479 - val_accuracy: 0.7333\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5933 - accuracy: 0.6991 - val_loss: 0.5331 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5889 - accuracy: 0.7047 - val_loss: 0.5207 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5830 - accuracy: 0.7009 - val_loss: 0.5152 - val_accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5856 - accuracy: 0.7028 - val_loss: 0.5220 - val_accuracy: 0.7333\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.7084 - val_loss: 0.5087 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5752 - accuracy: 0.7065 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5695 - accuracy: 0.7271 - val_loss: 0.5046 - val_accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5682 - accuracy: 0.7103 - val_loss: 0.5037 - val_accuracy: 0.7667\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5666 - accuracy: 0.7196 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5591 - accuracy: 0.7383 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.7383 - val_loss: 0.4953 - val_accuracy: 0.7333\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5592 - accuracy: 0.7178 - val_loss: 0.5027 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5614 - accuracy: 0.7290 - val_loss: 0.4956 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x287644692d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_size = 30\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "# setting  an early stopping mechanism\n",
    "# let's set patience=2, to be a bit tolerant against random validation loss increases\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "# fit the model\n",
    "\n",
    "nn_model.fit(x_train, # train inputs\n",
    "          y_train, # train targets\n",
    "          batch_size=batch_size, # batch size\n",
    "          epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
    "          callbacks=[early_stopping], # early stopping \n",
    "          validation_data=(x_val, y_val), # validation data\n",
    "          #verbose = 1 # making sure we get enough information about the training process\n",
    "          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7333\n",
      "accuracy = 0.7333333492279053\n"
     ]
    }
   ],
   "source": [
    "nn_loss,nn_accuracy=nn_model.evaluate(x_test,y_test)\n",
    "print(\"accuracy =\",nn_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('absenteeism_nn_model','wb')\n",
    "pickle.dump(nn_model,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III.USING RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "0.780952380952381\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf=RandomForestClassifier(n_estimators=40,random_state=42)\n",
    "clf_model=clf.fit(x_train,y_train)\n",
    "outputs=clf_model.predict(x_test)\n",
    "#print(outputs)\n",
    "rf_accuracy_matrix=outputs==y_test\n",
    "print(np.array([int(value) for value in rf_accuracy_matrix]))\n",
    "rf_accuracy=sum(rf_accuracy_matrix)/len(rf_accuracy_matrix)\n",
    "print(rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file=open('absenteeism_rf_model','wb')\n",
    "pickle.dump(clf_model,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "\t\t\tClassification reports\n",
      "\n",
      "\n",
      "1. logistic regression\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.78        57\n",
      "           1       0.76      0.65      0.70        48\n",
      "\n",
      "    accuracy                           0.74       105\n",
      "   macro avg       0.75      0.74      0.74       105\n",
      "weighted avg       0.74      0.74      0.74       105\n",
      "\n",
      "\n",
      "\n",
      "2. neural networ\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77        60\n",
      "           1       0.71      0.64      0.67        45\n",
      "\n",
      "    accuracy                           0.73       105\n",
      "   macro avg       0.73      0.72      0.72       105\n",
      "weighted avg       0.73      0.73      0.73       105\n",
      "\n",
      "\n",
      "\n",
      "3. random forest classifier\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81        57\n",
      "           1       0.80      0.69      0.74        48\n",
      "\n",
      "    accuracy                           0.78       105\n",
      "   macro avg       0.79      0.77      0.78       105\n",
      "weighted avg       0.78      0.78      0.78       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_report=classification_report(reg_model.predict(x_test),y_test)\n",
    "nn_report=classification_report((nn_model.predict(x_test)>0.5).astype(int),y_test)\n",
    "rf_report=classification_report(clf_model.predict(x_test),y_test)\n",
    "print(\"\\t\\t\\tClassification reports\")\n",
    "print(\"\\n\\n1. logistic regression\\n\\n\", log_report)\n",
    "print(\"\\n\\n2. neural network\\n\\n\", nn_report)\n",
    "print(\"\\n\\n3. random forest classifier\\n\\n\", rf_report)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
